
# АНАЛИЗ РЕЗУЛЬТАТОВ СРАВНЕНИЯ ПРОИЗВОДИТЕЛЬНОСТИ

## Результаты измерений:
- **PyTorch (GPU)**: 123.9 FPS (базовый уровень)
- **ONNX (GPU)**: 68.5 FPS 
- **ONNX (CPU)**: 26.8 FPS
- **INT8 (CPU)**: 22.2 FPS

## Коэффициенты ускорения (Speed-up):
- **ONNX-GPU**: 0.55x (замедление)
- **ONNX-CPU**: 0.22x (замедление)  
- **INT8-CPU**: 0.18x (замедление)

## Объяснение результатов:

### Почему PyTorch оказался быстрее ONNX?
1. **Оптимизации PyTorch**: Современные версии PyTorch имеют высокооптимизированные ядра для GPU
2. **Overhead конвертации**: ONNX добавляет дополнительный слой абстракции
3. **Специфика модели**: EfficientNet уже хорошо оптимизирован в PyTorch

### Почему INT8 медленнее чем Float32 на CPU?
1. **Overhead квантования**: Преобразование float32 → int8 требует дополнительных вычислений
2. **Маленькая модель**: Для небольших моделей like EfficientNet-B0 преимущества INT8 незначительны
3. **CPU оптимизации**: Современные CPU хорошо оптимизированы для float32 операций

### Когда ONNX и INT8 будут эффективны?
- **Крупные модели** (ResNet-152, Vision Transformers)
- **Специализированное железо** (NPU, Edge TPU)
- **Память ограничена** (мобильные устройства)
- **Batch processing** (обработка больших батчей)

## Терминология:

### FPS (Frames Per Second)
- Количество изображений, обрабатываемых за секунду
- **Чем выше - тем лучше**

### Speed-up (Ускорение)  
- Во сколько раз один формат быстрее другого
- **>1.0x - ускорение, <1.0x - замедление**

### Latency (Латентность)
- Время обработки одного изображения (в миллисекундах)  
- **Чем ниже - тем лучше**

## Выводы:
Для данной конфигурации (EfficientNet-B0 на GPU) **PyTorch показывает наилучшую производительность**. 
ONNX и INT8 оптимизации не дали преимущества из-за специфики модели и окружения.
